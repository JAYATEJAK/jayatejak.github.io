@InProceedings{10.1007/978-3-031-25072-9_17,
abbr={ECCVW},
author="Sreenivas, Manogna
and Takamuku, Sawa
and Biswas, Soma
and Chepuri, Aditya
and Vengatesan, Balasubramanian
and Natori, Naotake",
editor="Karlinsky, Leonid
and Michaeli, Tomer
and Nishino, Ko",
title="Improved Cross-Dataset Facial Expression Recognition by Handling Data Imbalance and Feature Confusion",
booktitle="ECCV Workshops",
year="2022",
publisher="Springer Nature Switzerland",
address="Cham",
pages="262--277",
abstract="Facial Expression Recognition (FER) models trained on one dataset (source) usually do not perform well on a different dataset (target) due to the implicit domain shift between different datasets. In addition, FER data is naturally highly imbalanced, with a majority of the samples belonging to few expressions like neutral, happy and relatively fewer samples coming from expressions like disgust, fear, etc., which makes the FER task even more challenging. This class imbalance of the source and target data (which may be different), along with other factors like similarity of few expressions, etc., can result in unsatisfactory target classification performance due to confusion between the different classes. In this work, we propose an integrated module, termed DIFC, which can not only handle the source Data Imbalance, but also the Feature Confusion of the target data for improved classification of the target expressions.We integrate this DIFC module with an existing Unsupervised Domain Adaptation (UDA) approach to handle the domain shift and show that the proposed simple yet effective module can result in significant performance improvement on four benchmark datasets for Cross-Dataset FER (CD-FER) task. We also show that the proposed module works across different architectures and can be used with other UDA baselines to further boost their performance.",
isbn="978-3-031-25072-9",
html={https://link.springer.com/chapter/10.1007/978-3-031-25072-9_17},
pdf={https://github.com/manogna-s/da-fer/blob/main/DIFC_WCPA_ECCVW'22.pdf},
selected={true}
}


@InProceedings{dss,
abbr={ICLRW},
author="Chakrabarty, Goirik
and Sreenivas, Manogna
and Biswas, Soma",
editor="Karlinsky, Leonid
and Michaeli, Tomer
and Nishino, Ko",
title="Domain Shift Signal for Low Resource Continuous Test-Time Adaptation",
booktitle="ICLR Workshops",
abstract="Test time domain adaptation has come to the forefront as a challenging scenario in recent times. Although single domain test-time adaptation has been well studied and shown impressive performance, this can be limiting when the model is deployed in a dynamic test environment. We explore this continual domain test time adaptation problem here. Specifically, we question if we can translate the effectiveness of single domain adaptation methods to continuous test-time adaptation scenario. We propose to use the given source domain trained model to continually measure the similarity between the feature representations of the consecutive batches. A domain shift is detected when this measure falls below a certain threshold, which we use as a trigger to reset the model back to source and continue test-time adaptation. We demonstrate the effectiveness of our method by performing experiments across datasets, batch sizes and different single domain test-time adaptation baselines. This can have a significant impact in a variety of applications, from healthcare and agriculture to transportation and finance. As a result, this research has the potential to greatly benefit developing countries by providing new tools and techniques for building more effective and efficient machine learning systems.",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="262--277",
isbn="978-3-031-25072-9",
selected={false}
}

@InProceedings{dss,
abbr={ICLRW},
author="Singh, Aakash
and Sreenivas, Manogna
and Biswas, Soma",
editor="Karlinsky, Leonid
and Michaeli, Tomer
and Nishino, Ko",
title="JumpStyle: A Framework for Data-Efficient Online Adaptation",
booktitle="ICLR Workshops",
abstract="Research in deep learning is restrictive in developing countries due to a lack of computational resources, quality training data, and expert knowledge, which negatively impacts the performance of deep networks. Moreover, these models are prone to suffer from distribution shift during testing. To address these challenges, this paper presents a novel approach for fine-tuning deep networks in a Domain Generalization setting. The proposed framework, JumpStyle, comprises two key components: (1) an innovative initialization technique that jumpstarts the adaptation process, and (2) the use of style-aware augmentation with pseudo-labeling, in conjunction with a simple and effective test-time adaptation baseline named Tent. Importantly, JumpStyle only requires access to a pre-trained model and is not limited by the training method. The effectiveness of this approach is extensively evaluated through experiments.",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="262--277",
isbn="978-3-031-25072-9",
selected={false}
}